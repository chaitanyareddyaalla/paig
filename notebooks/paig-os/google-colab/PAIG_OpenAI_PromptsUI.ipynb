{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitanyareddyaalla/paig/blob/main/notebooks/paig-os/google-colab/PAIG_OpenAI_PromptsUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e69bb50d-b560-4d92-b8aa-51b3d10fecad",
      "metadata": {
        "id": "e69bb50d-b560-4d92-b8aa-51b3d10fecad"
      },
      "source": [
        "# PAIG - Prompt/Reply Guardrails and Observability using OpenAI\n",
        "\n",
        "This notebook demonstrates how PAIG protects prompts and replies when using OpenAI, as well as how to achieve end-to-end observability.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **OpenAI API Key**: Required to make API calls to OpenAI.\n",
        "\n",
        "> The sample prompt is around 12 tokens, and the reply is 15 tokens. The notebook uses the model `gpt-4o-mini`, which currently costs \\$0.150 per 1 million input tokens and \\$0.600 per 1 million output tokens. Therefore, each prompt/reply costs approximately \\$0.00002.\n",
        "\n",
        "## Details\n",
        "\n",
        "This notebook covers the following steps:\n",
        "\n",
        "1. Install Python packages including PAIG Shield Server, PAIG Shield Client, OpenAI, and Spacy models.\n",
        "2. Start the PAIG Shield Server.\n",
        "3. Verify that the PAIG Shield Server is up and accepting requests.\n",
        "4. Download the sample application configuration from the PAIG Shield Server.\n",
        "5. Configure the OpenAI API Key.\n",
        "6. Write a simple application Using OpenAI.\n",
        "7. Write a simple application using OpenAI and the PAIG Shield Client.\n",
        "8. Test a sample prompt.\n",
        "9. Test sample prompts with UI.\n",
        "10. Review access audits in the PAIG Shield Server.\n",
        "11. Review Application Permissions.\n",
        "12. Check the reports.\n",
        "\n",
        "## Exceptions and Assumptions\n",
        "\n",
        "1. For simplicity, authentication to the PAIG Shield Server is turned off.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e821fc23-5f14-49f3-bacb-1d785cffa94b",
      "metadata": {
        "id": "e821fc23-5f14-49f3-bacb-1d785cffa94b"
      },
      "source": [
        "# 1. Install Python Packages\n",
        "\n",
        "This step installs the necessary Python packages for PAIG Shield Server, PAIG Shield Client, OpenAI, and Spacy.\n",
        "\n",
        "> Note:\n",
        "> 1. It might take a minute or more to download and install all the packages.\n",
        "> 2. After everything is installed, you might see a message to restart the runtime. You can ignore this message.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ba361f69-5dde-471f-ad0a-8daa9a049e88",
      "metadata": {
        "id": "ba361f69-5dde-471f-ad0a-8daa9a049e88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b4102e-e7b8-4dae-f469-e0ee968b8312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/759.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m757.8/759.0 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m759.0/759.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m938.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.6/525.6 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.3/149.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for alt-profanity-check (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\\n\\n\n",
            "Ignore the above messages to restart the runtime or kernel. Please continue to the next step\n"
          ]
        }
      ],
      "source": [
        "!pip install -qqq paig_client openai paig-server --no-warn-conflicts\n",
        "!python -m spacy download en_core_web_lg\n",
        "!echo \"\\n\\n\"\n",
        "!echo \"Ignore the above messages to restart the runtime or kernel. Please continue to the next step\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e2e478-7777-4f9d-9056-0262ef6de25e",
      "metadata": {
        "id": "34e2e478-7777-4f9d-9056-0262ef6de25e"
      },
      "source": [
        "# 2. Start the PAIG Shield Server\n",
        "\n",
        "The command line to start PAIG Shield Server is `paig run`. The server will be started in the background using Python subprocess.\n",
        "\n",
        "The default port used by PAIG Shield Server is 4545.\n",
        "\n",
        "> **Tip:** Detailed PAIG application logs can be found in a directory called \"logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "deccf140-571a-4330-a7d5-3c1d87cf1397",
      "metadata": {
        "id": "deccf140-571a-4330-a7d5-3c1d87cf1397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c3b990-85fd-47b3-ba07-c16055ca40c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started PAIG application with PID 1144\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "command = [\"paig\", \"run\"]\n",
        "\n",
        "# Start the PAIG application in the background\n",
        "# Note - Console logs are hidden using stdout parameter, please remove the stdout parameter to get console logs\n",
        "process = subprocess.Popen(command, stdout=subprocess.DEVNULL)\n",
        "\n",
        "print(f\"Started PAIG application with PID {process.pid}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "__XLMSPOLIDl",
      "metadata": {
        "id": "__XLMSPOLIDl"
      },
      "source": [
        "\n",
        "# 3. Verify that the PAIG Shield Server is Up and Accepting Requests\n",
        "\n",
        "This step ensures that the PAIG Shield Server is running and accepting requests. Once the server is up and running, it will print the URL for the PAIG Shield Server.\n",
        "\n",
        "> Note: The URL generated will be accessible from outside.  But it may take several seconds for the first load.  The portal will be opened within this Colab notebook in a later step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "NZQG-tzDLIDm",
      "metadata": {
        "id": "NZQG-tzDLIDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6971eaba-b6cd-43ef-d901-410eeb35af40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please wait while we confirm if your PAIG application is ready...\n",
            "Server is not ready yet, please hang on...\n",
            "Server is not ready yet, please hang on...\n",
            "Server is not ready yet, please hang on...\n",
            "Server is not ready yet, please hang on...\n",
            "Server is not ready yet, please hang on...\n",
            "Server is not ready yet, please hang on...\n",
            "Your PAIG application is now ready!.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "url = \"http://127.0.0.1:4545/\"\n",
        "\n",
        "print('Please wait while we confirm if your PAIG application is ready...')\n",
        "while True:\n",
        "  try:\n",
        "    response = requests.get(url, timeout=3)\n",
        "    response.raise_for_status()\n",
        "    break\n",
        "  except requests.RequestException:\n",
        "    print('Server is not ready yet, please hang on...')\n",
        "    time.sleep(3)\n",
        "\n",
        "server_url = str(eval_js(f\"google.colab.kernel.proxyPort({4545}, {{'cache': true}})\"))\n",
        "print(f'Your PAIG application is now ready!.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77325810-6ae1-47c8-b3d2-62bbf09efbe2",
      "metadata": {
        "id": "77325810-6ae1-47c8-b3d2-62bbf09efbe2"
      },
      "source": [
        "# 4. Download the Application Configuration from the PAIG Shield Server\n",
        "\n",
        "The PAIG Shield Server is bootstrapped with a sample GenAI application, which can be used to quickly test PAIG features. In this step, we will download the configuration file needed by the PAIG Shield Client. The configuration file is saved in the `privacera` sub-folder.\n",
        "\n",
        "> Note: The authentication is disabled in the colab mode only. So in colab mode, the API call to get the configuration will not be authorized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5d9ec3d1-b319-460f-aa2b-dc53bccbd746",
      "metadata": {
        "id": "5d9ec3d1-b319-460f-aa2b-dc53bccbd746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855bd184-6b45-435a-fb3a-4ce17f0c4847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-08 11:02:21--  http://127.0.0.1:4545/governance-service/api/ai/application/1/config/json/download\n",
            "Connecting to 127.0.0.1:4545... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/json]\n",
            "Saving to: ‘privacera/privacera-shield-PAIG-Demo-config.json’\n",
            "\n",
            "\r          privacera     [<=>                 ]       0  --.-KB/s               \rprivacera/privacera     [ <=>                ]   1.39K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-03-08 11:02:21 (317 KB/s) - ‘privacera/privacera-shield-PAIG-Demo-config.json’ saved [1424]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "CONFIG_URL=\"http://127.0.0.1:4545/governance-service/api/ai/application/1/config/json/download\"\n",
        "OUTPUT_FILE=\"privacera/privacera-shield-PAIG-Demo-config.json\"\n",
        "!mkdir -p privacera && wget -O $OUTPUT_FILE $CONFIG_URL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b6692c7-8fcd-4746-b56f-928d3098f929",
      "metadata": {
        "id": "5b6692c7-8fcd-4746-b56f-928d3098f929"
      },
      "source": [
        "# 5. Configure the OpenAI API Key\n",
        "\n",
        "Enter your OpenAI API key in the text box that will appear when you run this step. After you input the key, press __ENTER__.\n",
        "\n",
        "> Note: It is important to press __ENTER__ for your value to be accepted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "88429864-81be-47e8-9b7b-61d30cfb3f3b",
      "metadata": {
        "id": "88429864-81be-47e8-9b7b-61d30cfb3f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5dbed1-d12b-4722-fe94-5f1e988dd355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 Enter your OpenAI API key and hit Enter:··········\n",
            "OpenAI key has been entered. Now validating it...\n",
            "Connected to OpenAI successfully! How can I assist you today?\n",
            "If connection to OpenAI is successful, then proceed to the next step.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "openai_api_key = getpass(\"🔑 Enter your OpenAI API key and hit Enter:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "print(\"OpenAI key has been entered. Now validating it...\")\n",
        "\n",
        "from openai import OpenAI\n",
        "openai_model = \"gpt-4o-mini\"\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say Connected to OpenAI successfully!\",\n",
        "        }\n",
        "    ],\n",
        "    model=openai_model,\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)\n",
        "print(\"If connection to OpenAI is successful, then proceed to the next step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Write a Simple Application Using OpenAI"
      ],
      "metadata": {
        "id": "dqkLY6A3fpAA"
      },
      "id": "dqkLY6A3fpAA"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Set the OPENAI_API_KEY environment variable or set it here\n",
        "openai_client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# Function to generate AI responses\n",
        "def generate_response(PROMPT):\n",
        "\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=openai_model,\n",
        "            messages=[{\"role\": \"user\", \"content\": PROMPT}],\n",
        "            temperature=0\n",
        "        )\n",
        "        llm_response = response.choices[0].message.content\n",
        "        return llm_response\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# UI Components\n",
        "input_box = widgets.Textarea(\n",
        "    placeholder=\"Enter your prompt here...\",\n",
        "    description=\"Prompt:\",\n",
        "    layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "\n",
        "output_box = widgets.HTML(\n",
        "    value=\"<p><i>Your response will appear here...</i></p>\",\n",
        "    placeholder=\"Generated response\",\n",
        "    description=\"Output:\"\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate\")\n",
        "\n",
        "# Callback Function\n",
        "def on_generate_clicked(b):\n",
        "    user_prompt = input_box.value\n",
        "    if user_prompt.strip():\n",
        "        output_box.value = \"<p><i>Generating response...</i></p>\"\n",
        "        response = generate_response(user_prompt)\n",
        "        output_box.value = f\"<p><b>Response:</b><br>{response}</p>\"\n",
        "    else:\n",
        "        output_box.value = \"<p><i>Please enter a valid prompt.</i></p>\"\n",
        "\n",
        "# Link Button to Function\n",
        "generate_button.on_click(on_generate_clicked)\n",
        "\n",
        "# Display the UI\n",
        "display(HTML(\"<h2>Generative AI App</h2>\"))\n",
        "display(input_box)\n",
        "display(generate_button)\n",
        "display(output_box)\n"
      ],
      "metadata": {
        "id": "8alIV9lqr3bZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486,
          "referenced_widgets": [
            "18a1bfbe4b0f4fefa2c3eef9e5735152",
            "efba18e39aac403b9b51660f766ae389",
            "047e8a81a5054bc49fd9dfd6de7915fc",
            "6e35069537fb4d69bfd0c7716a574b15",
            "63686ef2fa43408f9aa0ffbfebdc0d4f",
            "f7a9fa542ba146ecb71d97266f1bddef",
            "d98fa0b6601c462bbe668f4bcc69d795",
            "773b92e0703b4d97ab11e6a57c385304",
            "1ebeb80a04b24545adf0ee48703adbb7"
          ]
        },
        "outputId": "aaaa25e0-b941-43b3-8649-7b848c50c4b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>Generative AI App</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Prompt:', layout=Layout(height='100px', width='100%'), placeholder='Enter your…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18a1bfbe4b0f4fefa2c3eef9e5735152"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Generate', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e35069537fb4d69bfd0c7716a574b15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<p><i>Your response will appear here...</i></p>', description='Output:', placeholder='Generated re…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d98fa0b6601c462bbe668f4bcc69d795"
            }
          },
          "metadata": {}
        }
      ],
      "id": "8alIV9lqr3bZ"
    },
    {
      "cell_type": "markdown",
      "id": "72d9da12-1a03-4cb4-8106-3fbbf4fa674d",
      "metadata": {
        "id": "72d9da12-1a03-4cb4-8106-3fbbf4fa674d"
      },
      "source": [
        "# 7. Write a Simple Application Using OpenAI and the PAIG Shield Client\n",
        "\n",
        "This section demonstrates a simple Python application that uses OpenAI for inference. The PAIG Shield is integrated within the application. The PAIG Shield client is initialized using the `setup()` method and is then used to validate the prompts and replies. In this basic GenAI application, the PAIG Shield's `check_access()` method needs to be explicitly called for the prompt and reply. However, when using frameworks like LangChain, PAIG will automatically instrument the code and call the `check_access()` method for all interactions with LLMs and RAGs.\n",
        "\n",
        "To enforce user or group-specific policies, the calling username should be set as the request context before processing the prompt. This can be done using the `with paig_shield_client.create_shield_context(username=username):` syntax.\n",
        "\n",
        "To stitch together related calls, an optional thread ID can be passed to the `check_access()` method to tie them together.\n",
        "\n",
        "Depending on the policies, the `check_access()` method will perform one of the following actions:\n",
        "\n",
        "1. If the user is not permitted to use the application or if there is a policy to deny contents which are inappropriate, having unauthorized sensitive information, or is of malicious intent, then the method will throw the exception `paig_client.exception.AccessControlException`. This exception can be caught, and an alternate reply can be returned to the caller.\n",
        "2. If the request is permitted but contains PII or sensitive information that is not authorized and needs to be redacted, the method will return the content with the PII or sensitive data elements redacted. This behavior is consistent for prompts, requests to RAGs, replies from RAGs, requests to LLMs, and replies from LLMs.\n",
        "3. If there are no policy violations, the content is returned without any alterations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dc0a93aa-fd6c-4bf7-9136-7d856f6109d1",
      "metadata": {
        "id": "dc0a93aa-fd6c-4bf7-9136-7d856f6109d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460ef758-b061-4c64-b4cd-88f1246fec85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PAIG Shield setup successfully completed! You can now proceed to the next step.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from paig_client import client as paig_shield_client\n",
        "from paig_client.model import ConversationType\n",
        "import paig_client.exception\n",
        "from openai import OpenAI\n",
        "import uuid\n",
        "\n",
        "# Set the OPENAI_API_KEY environment variable or set it here\n",
        "openai_client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# PAIG supports frameworks like LangChain and VectorDBs like Milvus, OpenSearch. The integration to be considered should be passed as the frameworks parameter.\n",
        "paig_shield_client.setup(frameworks=[])\n",
        "\n",
        "# Create a function which can be called for the prompts\n",
        "def query_as_user(username, prompt_text):\n",
        "    # Generate a random UUID which will be used to bind a prompt with a reply\n",
        "    privacera_thread_id = str(uuid.uuid4())\n",
        "\n",
        "    try:\n",
        "        with paig_shield_client.create_shield_context(username=username):\n",
        "            print(f\"PROMPT BY USER: {prompt_text}\")\n",
        "\n",
        "            # Validate prompt with Privacera Shield\n",
        "            updated_prompt_text = paig_shield_client.check_access(\n",
        "                text=prompt_text,\n",
        "                conversation_type=ConversationType.PROMPT,\n",
        "                thread_id=privacera_thread_id\n",
        "            )\n",
        "            updated_prompt_text = updated_prompt_text[0].response_text\n",
        "            if prompt_text != updated_prompt_text:\n",
        "                print(f\"Updated Prompt Text: {updated_prompt_text}\")\n",
        "            else:\n",
        "                print(\"PROMPT VALIDATION: Prompt has not been changed by PAIG.\")\n",
        "\n",
        "            # Call LLM with updated prompt text\n",
        "            PROMPT = f\"\"\"Use the following pieces of context to answer the question at the end.\n",
        "            {updated_prompt_text}\n",
        "            ANSWER:\n",
        "            \"\"\"\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=openai_model,\n",
        "                messages=[{\"role\": \"user\", \"content\": PROMPT}],\n",
        "                temperature=0\n",
        "            )\n",
        "            llm_response = response.choices[0].message.content\n",
        "            print(f\"LLM Response: {llm_response}\")\n",
        "\n",
        "            # Validate LLM response with Privacera Shield\n",
        "            updated_reply_text = paig_shield_client.check_access(\n",
        "                text=llm_response,\n",
        "                conversation_type=ConversationType.REPLY,\n",
        "                thread_id=privacera_thread_id\n",
        "            )\n",
        "            updated_reply_text = updated_reply_text[0].response_text\n",
        "            if llm_response != updated_reply_text:\n",
        "                print(f\"REPLY VALIDATION (UPDATED BY PAIG): {updated_reply_text}\")\n",
        "            else:\n",
        "                print(\"REPLY VALIDATION: The reply has not been updated by PAIG.\")\n",
        "            return updated_reply_text\n",
        "    except paig_client.exception.AccessControlException as e:\n",
        "        # If access is denied, this exception will be thrown. Handle it accordingly.\n",
        "        print(\"The query has been denied!\")\n",
        "        print(f\"AccessControlException: {e}\")\n",
        "        return \"DENIED: Prompt is not authorized.\"\n",
        "print(\"PAIG Shield setup successfully completed! You can now proceed to the next step.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "033b73ac-0a25-4a72-a32a-ba53c0d814db",
      "metadata": {
        "id": "033b73ac-0a25-4a72-a32a-ba53c0d814db"
      },
      "source": [
        "\n",
        "# 8. Test a Sample Prompt\n",
        "\n",
        "We will call the method `query_as_user` using a test user named `sally` with a sample prompt.\n",
        "\n",
        "Since we are using the demo application configuration, which has a policy that redacts PERSON_NAME from replies, any elements matching the policy in the LLM's reply will be redacted before responding back to the caller.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "43d6091c-0eee-4e7f-bd8f-3a9224f2d001",
      "metadata": {
        "id": "43d6091c-0eee-4e7f-bd8f-3a9224f2d001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a51c4c-6730-4881-c01d-c52ca9dbd22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROMPT BY USER: Who was the first President of USA and where did they live?\n",
            "PROMPT VALIDATION: Prompt has not been changed by PAIG.\n",
            "LLM Response: The first President of the United States was George Washington. He lived at Mount Vernon, his plantation located in Virginia.\n",
            "REPLY VALIDATION (UPDATED BY PAIG): The first President of the United States was <<PERSON>>. He lived at Mount Vernon, his plantation located in Virginia.\n",
            "REPLY TO USER=The first President of the United States was <<PERSON>>. He lived at Mount Vernon, his plantation located in Virginia.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Using test user named sally\n",
        "reply = query_as_user(\"sally\", \"Who was the first President of USA and where did they live?\")\n",
        "print(f\"REPLY TO USER={reply}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Test sample prompts with UI"
      ],
      "metadata": {
        "id": "7NWelYo7geSB"
      },
      "id": "7NWelYo7geSB"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import html\n",
        "\n",
        "\n",
        "# Function to generate AI responses\n",
        "def generate_response(PROMPT):\n",
        "\n",
        "    try:\n",
        "        llm_response = query_as_user(\"sally\", PROMPT)\n",
        "        return llm_response\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# UI Components\n",
        "input_box = widgets.Textarea(\n",
        "    placeholder=\"Enter your prompt here...\",\n",
        "    description=\"Prompt:\",\n",
        "    layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "\n",
        "output_box = widgets.HTML(\n",
        "    value=\"<p><i>Your response will appear here...</i></p>\",\n",
        "    placeholder=\"Generated response\",\n",
        "    description=\"Output:\"\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate\")\n",
        "\n",
        "# Callback Function\n",
        "def on_generate_clicked(b):\n",
        "    user_prompt = input_box.value\n",
        "    if user_prompt.strip():\n",
        "        output_box.value = \"<p><i>Generating response...</i></p>\"\n",
        "        response = generate_response(user_prompt)\n",
        "        sanitized_response = html.escape(response)\n",
        "        output_box.value = f\"<p><b>Response:</b><br>{sanitized_response}</p>\"\n",
        "    else:\n",
        "        output_box.value = \"<p><i>Please enter a valid prompt.</i></p>\"\n",
        "\n",
        "# Link Button to Function\n",
        "generate_button.on_click(on_generate_clicked)\n",
        "\n",
        "# Display the UI\n",
        "display(HTML(\"<h2>Generative AI App</h2>\"))\n",
        "display(input_box)\n",
        "display(generate_button)\n",
        "display(output_box)\n"
      ],
      "metadata": {
        "id": "q7t7Be52t6hC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "d04174ee2c4348008e7a6dfbcfc6e3f9",
            "12f37b3afa4c433eb56ab01e6391b878",
            "cf19e9bcdfa4431a87554c404af3ed63",
            "5b1282924e4944dcadfd70a2208b3582",
            "85ceffda63474e7aa7261678cf02ebf9",
            "d2189fe072c447e1bae29a1ed1483db2",
            "6984b0a9fbd04cc193751209300a2e7a",
            "c311c5cb24ef410ebf84e3fed821a20f",
            "51890c98ff24411d896524fc4beadbd1"
          ]
        },
        "outputId": "af23a17d-322c-4636-aa49-2eef19cbf345"
      },
      "id": "q7t7Be52t6hC",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>Generative AI App</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Prompt:', layout=Layout(height='100px', width='100%'), placeholder='Enter your…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d04174ee2c4348008e7a6dfbcfc6e3f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Generate', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b1282924e4944dcadfd70a2208b3582"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<p><i>Your response will appear here...</i></p>', description='Output:', placeholder='Generated re…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6984b0a9fbd04cc193751209300a2e7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROMPT BY USER: who are you\n",
            "\n",
            "PROMPT VALIDATION: Prompt has not been changed by PAIG.\n",
            "LLM Response: I am an AI language model created by OpenAI, designed to assist with a variety of questions and tasks by providing information and generating text based on the input I receive. How can I help you today?\n",
            "REPLY VALIDATION: The reply has not been updated by PAIG.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V1xv0cN3PT07",
      "metadata": {
        "id": "V1xv0cN3PT07"
      },
      "source": [
        "# 10. Review Access Audits in the PAIG Shield Server\n",
        "\n",
        "In this step, we will open the PAIG Server portal and check the audits. The portal will be embedded within this notebook.\n",
        "\n",
        "1. In the PAIG portal, navigate to the `Security > Access Audits` section. You will see the audit record from the above request.\n",
        "2. Click on the `More Details` button to see the details of the prompts sent by the application to the LLM and the responses coming from the LLM.\n",
        "3. PAIG will identify all PII and sensitive data and tag them.\n",
        "4. The default policy is to redact PERSON_NAME, so the president's name will be redacted before being sent to the caller.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lUoz5qhFPT07",
      "metadata": {
        "id": "lUoz5qhFPT07"
      },
      "outputs": [],
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "audit_url = f'{server_url}#/audits_security'\n",
        "IFrame(src=audit_url, width=\"100%\", height=1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F_ak1pfa7czI",
      "metadata": {
        "id": "F_ak1pfa7czI"
      },
      "source": [
        "\n",
        "# 11. Review Application Permissions\n",
        "\n",
        "1. In the portal, go to `Application -> AI Applications -> PAIG Demo`.\n",
        "2. Click on the `PERMISSIONS` tab at the top.\n",
        "3. You will see a policy stating that any reply containing `PERSON`, `EMAIL_ADDRESS`, or `PHONE_NUMBER` should be redacted.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddEvs8X_8ghM",
      "metadata": {
        "id": "ddEvs8X_8ghM"
      },
      "source": [
        "\n",
        "# 12. Check the Reports\n",
        "\n",
        "1. Click on `Reports -> Built-in Reports -> Sensitive Data Access Overview`.\n",
        "2. This report provides statistics on the PII and other sensitive data found in the prompts and replies.\n",
        "3. Similarly, the report `Summary of Users who accessed the GenAI Application` will provide details about the GenAI applications and the users accessing them.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18a1bfbe4b0f4fefa2c3eef9e5735152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_efba18e39aac403b9b51660f766ae389",
            "placeholder": "Enter your prompt here...",
            "rows": null,
            "style": "IPY_MODEL_047e8a81a5054bc49fd9dfd6de7915fc",
            "value": "which cricket team is best"
          }
        },
        "efba18e39aac403b9b51660f766ae389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "100px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "047e8a81a5054bc49fd9dfd6de7915fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e35069537fb4d69bfd0c7716a574b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generate",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_63686ef2fa43408f9aa0ffbfebdc0d4f",
            "style": "IPY_MODEL_f7a9fa542ba146ecb71d97266f1bddef",
            "tooltip": ""
          }
        },
        "63686ef2fa43408f9aa0ffbfebdc0d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7a9fa542ba146ecb71d97266f1bddef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d98fa0b6601c462bbe668f4bcc69d795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "Output:",
            "description_tooltip": null,
            "layout": "IPY_MODEL_773b92e0703b4d97ab11e6a57c385304",
            "placeholder": "Generated response",
            "style": "IPY_MODEL_1ebeb80a04b24545adf0ee48703adbb7",
            "value": "<p><b>Response:</b><br>Determining the \"best\" cricket team can be subjective and depends on various factors, including the format of the game (Test, One Day International, or T20), current form, historical performance, and individual player contributions. \n\nAs of my last update in October 2023, teams like India, Australia, and England have been consistently strong across formats. India has had a particularly strong performance in recent years, especially in limited-overs cricket. Australia has a rich cricketing history and remains competitive in all formats. England has also made significant strides, especially in white-ball cricket.\n\nFor the most current rankings and performance, it's best to check the latest ICC rankings or recent match results.</p>"
          }
        },
        "773b92e0703b4d97ab11e6a57c385304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ebeb80a04b24545adf0ee48703adbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d04174ee2c4348008e7a6dfbcfc6e3f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_12f37b3afa4c433eb56ab01e6391b878",
            "placeholder": "Enter your prompt here...",
            "rows": null,
            "style": "IPY_MODEL_cf19e9bcdfa4431a87554c404af3ed63",
            "value": "who are you\n"
          }
        },
        "12f37b3afa4c433eb56ab01e6391b878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "100px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "cf19e9bcdfa4431a87554c404af3ed63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b1282924e4944dcadfd70a2208b3582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generate",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_85ceffda63474e7aa7261678cf02ebf9",
            "style": "IPY_MODEL_d2189fe072c447e1bae29a1ed1483db2",
            "tooltip": ""
          }
        },
        "85ceffda63474e7aa7261678cf02ebf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2189fe072c447e1bae29a1ed1483db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6984b0a9fbd04cc193751209300a2e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "Output:",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c311c5cb24ef410ebf84e3fed821a20f",
            "placeholder": "Generated response",
            "style": "IPY_MODEL_51890c98ff24411d896524fc4beadbd1",
            "value": "<p><b>Response:</b><br>I am an AI language model created by OpenAI, designed to assist with a variety of questions and tasks by providing information and generating text based on the input I receive. How can I help you today?</p>"
          }
        },
        "c311c5cb24ef410ebf84e3fed821a20f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51890c98ff24411d896524fc4beadbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}